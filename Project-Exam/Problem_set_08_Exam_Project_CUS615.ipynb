{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saravrbic/CUS1156_Lab2/blob/main/Project-Exam/Problem_set_08_Exam_Project_CUS615.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I81n6Tk2bTd3"
      },
      "source": [
        "This notebook is part the of **Dr. Christoforos Christoforou's** course materials. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials or any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJd26bpK54JR"
      },
      "source": [
        "# Exam Project\n",
        "**Professor**: Dr. Christoforos Christoforou\n",
        "\n",
        "The objective of this project is to reproduce the data analysis method presented in the paper:\n",
        "\n",
        "* **\"Mining Big Data to Extract Patterns and Predict Real-Life Outcomes\"**\n",
        "by Michal Kosinski, Yilun Wang, Himabindu Lakkaraju, and Jure Leskovec.\n",
        "\n",
        "\n",
        "You must implement the analysis using python code. This notebook provides you with the starting code to load the data and guides you through the requirement and each sub-task of the analysis. To complete this project you are expected to:\n",
        "\n",
        "1. Carefully read the paper.\n",
        "2. Refer the class lecture where this paper was discussed in detail.\n",
        "3. Research various python libraries and utility functions needed to implement your analysis.\n",
        "4. Complete all the challenges outlined in this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA45dOL-iEkE"
      },
      "source": [
        "## Student Information \n",
        "Complete your information in the form provided below. This is visible in colab. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaAt15_OiVnw",
        "cellView": "form"
      },
      "source": [
        "#@title Strudent Information \n",
        "student_name = \"Sara Vrbic\" #@param {type:\"string\"}\n",
        "course_code = \"CUS 615\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGbeNmFGCCU"
      },
      "source": [
        "## Starter code - Configuring the analysis environment\n",
        "The code cells below provide you a starting code to setup the environment for you to complete this project's tasks.\n",
        "\n",
        "In particular, the code downloads the three dataset associated with this project and stores them in the folder `/content/sample_data/`. The data files from the paper comprise the `likes.csv` file, the `users.csv` file and the `users-likes.csv`; description of each data file is availabile in the paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB33C_sJ5p4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5adbb1c9-4221-4996-fe8b-50c96c1f4761"
      },
      "source": [
        "#\n",
        "# Run this sell to download the data for your analysis. \n",
        "#\n",
        "!wget -O /content/sample_data/sample_dataset.zip https://osf.io/9m87k/download\n",
        "!unzip /content/sample_data/sample_dataset.zip -d /content/sample_data/\n"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-03 00:08:41--  https://osf.io/9m87k/download\n",
            "Resolving osf.io (osf.io)... 35.190.84.173\n",
            "Connecting to osf.io (osf.io)|35.190.84.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1 [following]\n",
            "--2023-05-03 00:08:41--  https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1\n",
            "Resolving files.osf.io (files.osf.io)... 35.186.214.196\n",
            "Connecting to files.osf.io (files.osf.io)|35.186.214.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314322145 (300M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/sample_dataset.zip’\n",
            "\n",
            "/content/sample_dat 100%[===================>] 299.76M  44.5MB/s    in 8.6s    \n",
            "\n",
            "2023-05-03 00:08:50 (34.7 MB/s) - ‘/content/sample_data/sample_dataset.zip’ saved [314322145/314322145]\n",
            "\n",
            "Archive:  /content/sample_data/sample_dataset.zip\n",
            "replace /content/sample_data/likes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_k8ynI123ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e401b417-4e4e-4c1c-f67e-ff65884e95a8"
      },
      "source": [
        "pip install factor_analyzer\n"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: factor_analyzer in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2022.7.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (20.23.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (2.5.23)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (3.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (6.0)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (1.7.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->factor_analyzer) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->factor_analyzer) (1.16.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (3.3.0)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (3.12.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (0.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO_u3jLnJ6ut"
      },
      "source": [
        "#\n",
        "# You will likely need the following python packages when implementing this project.\n",
        "# Add any additional package as you deem necessary \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "from factor_analyzer import Rotator\n",
        "\n",
        "# Additional package you want to use:\n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc6GFQPhKTUn"
      },
      "source": [
        "## Challenge 1 : Load the data into dataframes\n",
        "In this challenge you are expected to load the data from the raw files into the following variables:\n",
        "-  `users` : should reference a dataframe with the data in the `users.csv` file\n",
        "-  `likes` : should reference a dataframe with the data in the `likes.csv` file\n",
        "-  `ul` : should reference a dataframe with the data in `users.csv` file\n",
        "\n",
        "Then print the top 10 rows of reach dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jYTqf_Mabo"
      },
      "source": [
        "\n",
        "datafile1 = './sample_data/likes.csv'  \n",
        "datafile2 =  './sample_data/users.csv'  \n",
        "datafile3 = './sample_data/users-likes.csv'\n",
        "\n",
        "likes = pd.read_csv(datafile1)\n",
        "users = pd.read_csv(datafile2)\n",
        "ul = pd.read_csv(datafile3)\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlspDtjMf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "788a6236-e64f-4cc8-eab2-de0616430b17"
      },
      "source": [
        "likes.head(10)\n",
        "users.head(10)\n",
        "ul.head(10)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             userid                            likeid\n",
              "0  71bc7c0901488aec6d30f0add257e7c5  3c1636c878e6eb2acfd00c6b61086e38\n",
              "1  978ab8e90c4d6ad1a48ef5c973b62f4d  feca46ddb8ef04f86172ace0cb7e004c\n",
              "2  85123b0e358907725cf19a2cb0ec3983  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "3  ce110562b3e2f7e5cad3775b32d9caa5  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "4  8188d20745471273fa69ba44a5b28473  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "5  e9c621f322640e5f3b3842d19b38aaa8  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "6  f0c99cfcdbda49dc424848666c6b31a9  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "7  7de7b4609c6b51d956d27050c958d885  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "8  05ce4ab49d90139ec1f7af9f0255c9c6  b65f46d64c688fe98bdbcf93a76a71fc\n",
              "9  051caa763b05e64d4c8699078e942dfd  9c5c8bb82d2cd46fbd7582f944fe370e"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6781730-c121-465a-9e2d-02b329baac40\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>likeid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>71bc7c0901488aec6d30f0add257e7c5</td>\n",
              "      <td>3c1636c878e6eb2acfd00c6b61086e38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>978ab8e90c4d6ad1a48ef5c973b62f4d</td>\n",
              "      <td>feca46ddb8ef04f86172ace0cb7e004c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>85123b0e358907725cf19a2cb0ec3983</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ce110562b3e2f7e5cad3775b32d9caa5</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8188d20745471273fa69ba44a5b28473</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>e9c621f322640e5f3b3842d19b38aaa8</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>f0c99cfcdbda49dc424848666c6b31a9</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7de7b4609c6b51d956d27050c958d885</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>05ce4ab49d90139ec1f7af9f0255c9c6</td>\n",
              "      <td>b65f46d64c688fe98bdbcf93a76a71fc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>051caa763b05e64d4c8699078e942dfd</td>\n",
              "      <td>9c5c8bb82d2cd46fbd7582f944fe370e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6781730-c121-465a-9e2d-02b329baac40')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6781730-c121-465a-9e2d-02b329baac40 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6781730-c121-465a-9e2d-02b329baac40');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJYv5EFuMfkL"
      },
      "source": [
        "## Challenge 2: Create the sparse user-likes matrix \n",
        "Create a **sparse matrix** that stores the data for the user-likes associations as described in the paper. The name of the user-likes matrix must be `M`, to keep the naming convention used in the paper. It is important that to store the data in a sparse matrix; you might need to research the topic of using sparse matrices in python (i.e. look at the `scipy.sparse` package and the `csr_matrix` class). *Hint: For this challenge,  you might find  the `merge` method from `pandas` library useful*. \n",
        "\n",
        "Once you create the matrix print its shape on the answer summary cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnI9ocfkYox-"
      },
      "source": [
        "r = pd.merge(left=ul, right=users.reset_index(), on='userid', how=\"left\")['index']\n",
        "c = pd.merge(left=ul, right=likes.reset_index(), on=\"likeid\", how=\"left\")['index']\n",
        "M = csr_matrix((np.ones((len(ul))), (r,c)))"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYGEacxYvho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5b0ac0-9a35-4c9c-c12d-ccf3a73eb606"
      },
      "source": [
        "M.shape\n"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(110728, 1580284)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKJldPiWY5Tr"
      },
      "source": [
        "## Challege 3: Trim the sparse user-likes matrix M.\n",
        "The paper calls for the matrix `M` to be trimmed (i.e. to remove users which did not like a minimum number of posts and posts that did not receive a minimum number of likes). In this challenge, you are expected to implement the trimming preprocessing step as described in the paper. The resulting matrix must be a sparse matrix. *Hint: you might want to research to index slice sparse matrices in python*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_M8CC9-cXZs"
      },
      "source": [
        "y=users.political\n",
        "#Trimming the sparse matrix to get rid of minimum number of likes/users who didn't like a minimum number os posts\n",
        "while True:\n",
        "    i = M.shape[0] + M.shape[1]\n",
        "    y = y[np.array(np.sum(M, axis=1) >= 50).flatten()]\n",
        "    M = M[np.array(np.sum(M, axis=1) >= 50).flatten(), :]\n",
        "    M = M[:,np.array(np.sum(M, axis=0) >= 150).flatten()]\n",
        "    if i == (M.shape[0] + M.shape[1]):\n",
        "        break"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "RmTkOrdQ12rC"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywuRl88caaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb08497-aa5d-46bf-b48d-21a0ac4adf11"
      },
      "source": [
        "M.shape\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19742, 8523)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz7ptmgQTpMM",
        "outputId": "a399d3d4-a74a-4d2d-e383-f747a60b7d3c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19742, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPCmSbfCcs4P"
      },
      "source": [
        "## Challenge 4:  Split the sparse matrix into a training and testing matrices\n",
        "To build a prediction model the paper calls for separating the data matrix (i.e. the user-like matrix) into a training and testing matrices. As part of this challenge, you need to create a training matrix `M_train` that includes the preferences of 80% of the users, and a testing matrix `M_test` that include the preferences of the remaining 20% of the users in the dataset. Both matrices `M_train` and `M_test` must be stored as sparse matrices. User will be randomly assigned to the training or testing set.\n",
        "\n",
        "Print the shapes of the `M_train` and `M_test` matrices.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1avbiXTygvz"
      },
      "source": [
        "#Splitting the matrix into M_train,M_test,y_train,y_test. Using a 80/20 split, random state=15\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csr_matrix\n",
        "M_train,M_test,y_train,y_test=train_test_split(M,y,test_size=0.2,random_state=15)\n"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTijUQ0ykDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924d9001-5d3b-43a6-c249-2f230bdda494"
      },
      "source": [
        "M_train.shape"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15793, 8523)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C12ZOruhj5U3",
        "outputId": "c299b80e-e4b2-4264-d7c9-0bba61885b2d"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3949, 8523)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHzVhY-lULhJ",
        "outputId": "e3f7a752-22da-4e94-8f2d-54a8e33863e4"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15793, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTRVcaCeUO8W",
        "outputId": "d75666ee-cd30-484c-a7b8-8142b26adc22"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3949, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cPhHjAdciZP"
      },
      "source": [
        "## Challege 5 : Reduce the dimensionality of the M_train matrix using SVD\n",
        "\n",
        "In this challenge, you must use singular value decomposition (SVD) to reduce the dimensionality of the training matrix `M_train`. Remember that `M_train` is encoded as a sparse matrix so you would need to use an appropriate implementation of the SVD for sparse matrices. Your output should be the matrices `U`, `S` and `Vt` that correspond to the left singular vectors, the singular values, and the right singular vectors, respectively. You must specify a parameter `k` that defines the number of reduced dimensions you want to keep.\n",
        "\n",
        "Print the shapes of the `U`, `S` and `Vt` matrices and the value you selected for parameter `k`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NlzhH21mWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afd980d-8147-42a3-81ff-6add73e299a4"
      },
      "source": [
        "k = 15\n",
        "U, S, Vt = svds(M_train, k=k, random_state=15)\n",
        "#Seeing the shape of the different matrices\n",
        "print(\"Shape of U:\", U.shape)\n",
        "print(\"Shape of S:\", S.shape)\n",
        "print(\"Shape of Vt:\", Vt.shape)\n",
        "print(\"Value of k:\", k)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of U: (15793, 15)\n",
            "Shape of S: (15,)\n",
            "Shape of Vt: (15, 8523)\n",
            "Value of k: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJa9qQVr1vmv"
      },
      "source": [
        "## Challege 6 : Use the varimax algorithm to rotate the SVD dimensions. \n",
        "Use the varimax algorithm to rotate the SVD dimensions as described in the paper. A good python library that implements varimax algorithm is the `factor_analyzer` and its `Rotator` class (already installed in this notebook for your in the started cell above); i.e. using `rotator = Rotator(method='varimax')`. Store the varimax SVD into the matrices `U_rot` and `V_rot` respectively. *Hint: you can apply varimax of `Vt` to get `V_rot` and then multiply `M` by  `Vt_rot` to obtain the `U_rot` (as done in the paper); you might want to research hot to user the `Rotator` class*. \n",
        "\n",
        "Print the shapes of the matrices `U_rot` and `V_rot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGmf_MN4KH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d381539-0289-45c4-b48d-aaba6c45a4b3"
      },
      "source": [
        "from factor_analyzer import Rotator\n",
        "V = Vt.T\n",
        "rotator = Rotator(method='varimax')\n",
        "V_rot = rotator.fit_transform(V)\n",
        "#Vt_rot = V_rot.T\n",
        "U_rot = M_train.dot(V_rot)\n",
        "\n",
        "# Print the shapes of U_rot and V_rot\n",
        "print('Shape of U_rot:', U_rot.shape)\n",
        "print('Shape of V_rot:', Vt.shape)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of U_rot: (15793, 15)\n",
            "Shape of V_rot: (15, 8523)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp0BpsHd4wfg"
      },
      "source": [
        "## Challenge 7 : Train two predictive model to predict the political  affilication of users.\n",
        "Build a predictive model that predicts the political affiliation of the users given the user's post preferences (as those are captured in the paper's dataset). To train your model you can use data from matrix `M_train` only. You are expected to use two different predictive models of your choice (i.e. Knn, SVM, Logistic Regression or some other model of your choice).\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Apply any necessary preprocessing to handle missing values.\n",
        "- The models must be applied on the reduced-dimensional feature generated by your analysis above (i.e. use the singular rotated singular dimensions)\n",
        "- Use cross-validation for model selection (i.e. to identify optimal parameters for your model, or any meta-parameters)\n",
        "- Report training and cross-validation performance of the two models as well as the optimal parameters for your model identified by cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQ_wRcs7pA7"
      },
      "source": [
        "**FIRST MODEL TRAINING: Use the cells below to train the predictive model using the first model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK6Yd4hf7fAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b75c34d-bfdc-4a92-c733-98cb9060a28a"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#initilizing \n",
        "X_train = M_train.dot(Vt.T)\n",
        "X_test = M_test.dot(Vt.T)\n",
        "\n",
        "#getting rid of the null values\n",
        "X_train=pd.DataFrame(X_train)\n",
        "X_train['y']=y_train\n",
        "X_train=X_train[X_train['y'].isnull()==False]\n",
        "X_train['y'].isnull()\n",
        "y_train=X_train['y']\n",
        "X_train=X_train.drop('y',axis=1)\n",
        "\n",
        "\n",
        "X_test=pd.DataFrame(X_test)\n",
        "X_test['y']=y_test\n",
        "X_test=X_test[X_test['y'].isnull()==False]\n",
        "X_test['y'].isnull()\n",
        "y_test=X_test['y']\n",
        "X_test=X_test.drop('y',axis=1)\n",
        "\n",
        "# Check the shapes of the training and test sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (3205, 15)\n",
            "Shape of y_train: (3205,)\n",
            "Shape of X_test: (231, 15)\n",
            "Shape of y_test: (231,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHxGNOFf83pO"
      },
      "source": [
        "**FIRST MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your first model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDrzCnB99i9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b6cd75-c55d-474f-f251-946525642bc8"
      },
      "source": [
        "#Performing SVM\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "model  = svm.SVC(C=1.0,kernel='rbf',gamma='scale')\n",
        "model.fit(X_train,y_train)\n",
        "y_pred= model.predict(X_test)\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7445887445887446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrkRGd1t-ISp"
      },
      "source": [
        "**SECOND MODEL TRAINING: Use the cells below to train the predictive model using the second model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR8wUcci-Lnj"
      },
      "source": [
        "#Performing KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "  \n",
        "n_neighbors = 43  \n",
        "\n",
        "cv = StratifiedKFold(n_splits=n_splits, random_state=15, shuffle=True)\n",
        "model=KNeighborsClassifier(n_neighbors=k)\n",
        "cv_acc=cross_val_score(estimator=model,\n",
        "                           X=X_train,\n",
        "                           y=y_train,\n",
        "                           cv=cv,\n",
        "                           n_jobs=-1)\n",
        "scores.append(np.mean(cv_acc))\n"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RcnRV85-SkD"
      },
      "source": [
        "**SECOND MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your second model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy was: {:.2f}\".format(max(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xmBgaMKywY8",
        "outputId": "b46485ff-d484-43ad-f7a1-6e192c6878a6"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy was: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D6o6Cy-8xKp"
      },
      "source": [
        "## Challenge 8 Apply your model in the independent test set.\n",
        "User the cells below to apply your two predictive models on the test dataset `M_test` and report testing accuracy for each model.\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Project each observation in the test dataset `M_test` onto the reduced-dimensional features space.\n",
        "- Apply each on of your model to make predict each user's political preference (for users in the testing set only)\n",
        "- Report testing accuracy on each of your models.\n",
        "- Make an assessment as to which model is better and whether either of your models is overfitted or under-fitted."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=KNeighborsClassifier(n_neighbors=43)\n",
        "X.fit(X_train,y_train)\n",
        "y_pred=X.predict(X_test)"
      ],
      "metadata": {
        "id": "at2XJIW1zadm"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=accuracy_score(y_test,y_pred)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7DZJTXT4stg",
        "outputId": "9961703a-7f2a-4f3c-ae35-04d7a1c57415"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7445887445887446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "SVMA = model.score(X_test, y_test)\n",
        "\n",
        "print(\"Test accuracy:\", SVMA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vlYonbc6mep",
        "outputId": "bf77a0ba-568c-4c97-e77e-9e86486eb0de"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqDyqK9qb4Ze"
      },
      "source": [
        "# END OF EXAM/CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha290eSXRT9R"
      },
      "source": [
        "\n",
        "*Copyright Statement*: Copyright © 2020 Christoforou. The materials provided by the instructor of this course, including this notebook, are for the use of the students enrolled in the course. Materials are presented in an educational context for personal use and study and should not be shared, distributed, disseminated or sold in print — or digitally — outside the course without permission. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials  as well as any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_ijPXabKsG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}